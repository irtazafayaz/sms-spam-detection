{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c20051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08501f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/spam.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d287ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30857fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a05792",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'v1': 'target', 'v2': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a7daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate values\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ed869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50acbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['target'] = le.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa3bba5",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3066ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed3243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdec12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(df['target'].value_counts(), labels=['ham', 'spam'], autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba67f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since data is imbalanced, we will use stratified sampling while splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4024295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt_tab', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e9d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_characters'] = df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb631123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86c5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_words'] = df['text'].apply(lambda x: nltk.word_tokenize(x)).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72694f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_sentences'] = df['text'].apply(lambda x: nltk.sent_tokenize(x)).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbb65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['target'] == 0][['num_characters', 'num_words', 'num_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.histplot(df[df['target'] == 0]['num_characters'], color='blue', label='Ham')\n",
    "sns.histplot(df[df['target'] == 1]['num_characters'], color='red', label='Spam')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd511a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n",
    "plt.figure(figsize=(20, 6))\n",
    "sns.histplot(df[df['target'] == 0]['num_words'], color='blue', label='Ham')\n",
    "sns.histplot(df[df['target'] == 1]['num_words'], color='red', label='Spam')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888eb004",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.select_dtypes(include=['number']).corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr, annot=True, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed485ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d6618",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7aa89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef95d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return \" \".join([\n",
    "        ps.stem(token) \n",
    "        for token in tokens \n",
    "        if token.isalnum() and token not in stop_words and token not in string.punctuation \n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c710d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_text('can you come to the epstein island tommorrow? loving dancing %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04853fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c990139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transformed_text'] = df['text'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18307838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c7ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e44f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wc = WordCloud(width=500, height=500, min_font_size=10, background_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f8a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = wc.generate(df[df['target'] == 1]['transformed_text'].str.cat(sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa40bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7764f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607cdd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['target'] == 1]['transformed_text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_corpus = []\n",
    "spam_words_list = df[df['target'] == 1]['transformed_text'].tolist()\n",
    "\n",
    "for text in spam_words_list:\n",
    "    for word in text.split():\n",
    "        spam_corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spam_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "pd.DataFrame(Counter(spam_corpus).most_common(30), columns=['word', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c1688",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='word', y='count', data=pd.DataFrame(Counter(spam_corpus).most_common(30), columns=['word', 'count']))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a61ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_corpus = []\n",
    "ham_words_list = df[df['target'] == 0]['transformed_text'].tolist()\n",
    "\n",
    "for text in ham_words_list:\n",
    "    for word in text.split():\n",
    "        ham_corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47c269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='word', y='count', data=pd.DataFrame(Counter(ham_corpus).most_common(30), columns=['word', 'count']))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af72270",
   "metadata": {},
   "source": [
    "# 4. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "70b8cf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "cv = TfidfVectorizer(max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de34364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training\n",
    "X = cv.fit_transform(df['transformed_text']).toarray()\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd25383a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 4135, Test samples: 1034\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "print(f\"Train samples: {len(X_train)}, Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eddb57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dd8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_gnb))\n",
    "print(\"Precision Score:\", precision_score(y_test, y_pred_gnb))\n",
    "print(\"Confusion Matrix\", confusion_matrix(y_test, y_pred_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.fit(X_train, y_train)\n",
    "y_pred_mnb = mnb.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_mnb))\n",
    "print(\"Precision Score:\", precision_score(y_test, y_pred_mnb))\n",
    "print(\"Confusion Matrix\", confusion_matrix(y_test, y_pred_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb.fit(X_train, y_train)\n",
    "y_pred_bnb = bnb.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_bnb))\n",
    "print(\"Precision Score:\", precision_score(y_test, y_pred_bnb))\n",
    "print(\"Confusion Matrix\", confusion_matrix(y_test, y_pred_bnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55065bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6719d9ef",
   "metadata": {},
   "source": [
    "# 5. Model Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f714da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth=5)\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
    "abc = AdaBoostClassifier(n_estimators=50, random_state=2)\n",
    "gbc = GradientBoostingClassifier(n_estimators=50, random_state=2)\n",
    "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
    "bc = BaggingClassifier(n_estimators=50, random_state=2)\n",
    "xgbc = XGBClassifier(n_estimators=50, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ab014",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'SVC': svc,\n",
    "    'KNC': knc,\n",
    "    'MNB': mnb,\n",
    "    'DTC': dtc,\n",
    "    'RFC': rfc,\n",
    "    'ABC': abc,\n",
    "    'GBC': gbc,\n",
    "    'ETC': etc,\n",
    "    'BC': bc,\n",
    "    'XGBC': xgbc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461c88b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    return accuracy, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1db42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classifier(svc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e708914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reusable function to run all classifiers and return results ---\n",
    "def run_all_classifiers(clfs, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Train all classifiers and return a dict with model names as keys \n",
    "    and (accuracy, precision) as values\"\"\"\n",
    "    results = {}\n",
    "    for name, clf in clfs.items():\n",
    "        accuracy, precision = train_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "        results[name] = (accuracy, precision)\n",
    "        print(f\"{name}: Accuracy={accuracy:.4f}, Precision={precision:.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fc604cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Experiment: original ===\n",
      "SVC: Accuracy=0.9758, Precision=0.9748\n",
      "KNC: Accuracy=0.9052, Precision=1.0000\n",
      "MNB: Accuracy=0.9710, Precision=1.0000\n",
      "DTC: Accuracy=0.9284, Precision=0.8200\n",
      "RFC: Accuracy=0.9758, Precision=0.9829\n",
      "ABC: Accuracy=0.9246, Precision=0.8488\n",
      "GBC: Accuracy=0.9468, Precision=0.9192\n",
      "ETC: Accuracy=0.9749, Precision=0.9746\n",
      "BC: Accuracy=0.9584, Precision=0.8682\n",
      "XGBC: Accuracy=0.9671, Precision=0.9483\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store results from all experiments\n",
    "# Key = experiment name, Value = dict of {model_name: (accuracy, precision)}\n",
    "all_experiments = {}\n",
    "\n",
    "# --- Experiment 1: Original (default TfidfVectorizer) ---\n",
    "print(\"=== Experiment: original ===\")\n",
    "all_experiments['original'] = run_all_classifiers(clfs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "16336156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Experiment: max_ft_3000 ===\n",
      "SVC: Accuracy=0.9758, Precision=0.9748\n",
      "KNC: Accuracy=0.9052, Precision=1.0000\n",
      "MNB: Accuracy=0.9710, Precision=1.0000\n",
      "DTC: Accuracy=0.9313, Precision=0.8252\n",
      "RFC: Accuracy=0.9758, Precision=0.9829\n",
      "ABC: Accuracy=0.9246, Precision=0.8488\n",
      "GBC: Accuracy=0.9468, Precision=0.9192\n",
      "ETC: Accuracy=0.9749, Precision=0.9746\n",
      "BC: Accuracy=0.9584, Precision=0.8682\n",
      "XGBC: Accuracy=0.9671, Precision=0.9483\n"
     ]
    }
   ],
   "source": [
    "# --- Experiment 2: TfidfVectorizer with max_features=3000 ---\n",
    "# (Re-using same X_train, X_test since cv was already set to max_features=3000)\n",
    "print(\"=== Experiment: max_ft_3000 ===\")\n",
    "all_experiments['max_ft_3000'] = run_all_classifiers(clfs, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "46440168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_original</th>\n",
       "      <th>Precision_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNC</td>\n",
       "      <td>0.905222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNB</td>\n",
       "      <td>0.970986</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RFC</td>\n",
       "      <td>0.975822</td>\n",
       "      <td>0.982906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.975822</td>\n",
       "      <td>0.974790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ETC</td>\n",
       "      <td>0.974855</td>\n",
       "      <td>0.974576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBC</td>\n",
       "      <td>0.967118</td>\n",
       "      <td>0.948276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.919192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BC</td>\n",
       "      <td>0.958414</td>\n",
       "      <td>0.868217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABC</td>\n",
       "      <td>0.924565</td>\n",
       "      <td>0.848837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC</td>\n",
       "      <td>0.928433</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy_original  Precision_original\n",
       "1   KNC           0.905222            1.000000\n",
       "2   MNB           0.970986            1.000000\n",
       "4   RFC           0.975822            0.982906\n",
       "0   SVC           0.975822            0.974790\n",
       "7   ETC           0.974855            0.974576\n",
       "9  XGBC           0.967118            0.948276\n",
       "6   GBC           0.946809            0.919192\n",
       "8    BC           0.958414            0.868217\n",
       "5   ABC           0.924565            0.848837\n",
       "3   DTC           0.928433            0.820000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Helper function to build comparison dataframe from all experiments ---\n",
    "def build_comparison_df(all_experiments):\n",
    "    \"\"\"Takes the all_experiments dict and builds a single comparison DataFrame.\n",
    "    Each experiment adds Accuracy_<name> and Precision_<name> columns.\"\"\"\n",
    "    \n",
    "    # Get model names from first experiment\n",
    "    model_names = list(list(all_experiments.values())[0].keys())\n",
    "    \n",
    "    comparison = pd.DataFrame({'Model': model_names})\n",
    "    \n",
    "    for exp_name, results in all_experiments.items():\n",
    "        comparison[f'Accuracy_{exp_name}'] = [results[m][0] for m in model_names]\n",
    "        comparison[f'Precision_{exp_name}'] = [results[m][1] for m in model_names]\n",
    "    \n",
    "    # Sort by the last experiment's precision\n",
    "    last_exp = list(all_experiments.keys())[-1]\n",
    "    return comparison.sort_values(by=f'Precision_{last_exp}', ascending=False)\n",
    "\n",
    "# Build and display comparison so far\n",
    "comparison_df = build_comparison_df(all_experiments)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359682eb",
   "metadata": {},
   "source": [
    "### 2. Lets try with scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8898e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=2\n",
    ")\n",
    "\n",
    "print(\"=== Experiment: minmax_scaled ===\")\n",
    "all_experiments['minmax_scaled'] = run_all_classifiers(\n",
    "    clfs, X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d092eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = build_comparison_df(all_experiments)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afbedb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# It means scaling the features did not improve the performance of the models. \n",
    "# In fact, it seems to have slightly decreased the precision for most models. \n",
    "# This suggests that for this particular dataset and feature representation (TF-IDF), scaling may not be necessary or beneficial. \n",
    "# However, it's always good to experiment with different preprocessing techniques as their impact can vary based on the data and model used.\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df729994",
   "metadata": {},
   "source": [
    "### 3. Lets try with adding more features like num_characters, num_words, num_sentences to the original X and see if it improves the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab682f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nc = np.hstack((X, df['num_characters'].values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "    X_nc, y, test_size=0.2, random_state=2\n",
    ")\n",
    "\n",
    "print(\"=== Experiment: adding num_characters ===\")\n",
    "all_experiments['num_characters'] = run_all_classifiers(\n",
    "    clfs, X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = build_comparison_df(all_experiments)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616545f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nw = np.hstack((X, df['num_words'].values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e336a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "    X_nw, y, test_size=0.2, random_state=2\n",
    ")\n",
    "\n",
    "print(\"=== Experiment: adding num_words ===\")\n",
    "all_experiments['num_words'] = run_all_classifiers(\n",
    "    clfs, X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c21a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = build_comparison_df(all_experiments)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec1222",
   "metadata": {},
   "source": [
    "### 4. Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e99180",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier(estimators=[('svc', svc), ('mnb', mnb), ('rfc', rfc)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c4e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0c7300",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting.predict(X_test)\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision Score:\", precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d322b6",
   "metadata": {},
   "source": [
    "### 5. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ebc86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('svc', svc), ('nb', mnb), ('et', etc)]\n",
    "final_estimator = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ed941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df228866",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(estimators=estimators, final_estimator=final_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ae860",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision Score:\", precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "918aa4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(mnb, open('model.pkl', 'wb'))\n",
    "pickle.dump(cv, open('vectorizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b243deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sms-spam-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
